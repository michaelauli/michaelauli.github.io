---
layout: default
title: Michael Auli
picture: headshot_2019
news:
  -
    >
      <a href="https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision/">wav2vec-U</a> enables speech recognition performance competitive to the best systems trained on 960h of labeled data from only two years ago and was accepted for oral presentation at NeurIPS 2021.
  -
    >
      I recently gave a <a href="talks/wav2vec-ssl.pdf">talk about wav2vec</a> at MIT, CMU and the University of Edinburgh.
  -
    >
      <a href="https://arxiv.org/abs/2006.11477">wav2vec 2.0</a> enables speech recognition systems using just 10 minutes of transcribed data. Applying it to <a href="https://arxiv.org/abs/2006.13979">cross-lingual training</a> gives nice results on CommonVoice and BABEL.
  -
    >
      Our papers on <a href="https://arxiv.org/pdf/1910.10073">Depth-Adaptive Transformers</a> and <a href="https://arxiv.org/pdf/1910.05453">vq-wav2vec</a> have been accepted to ICLR 2020.
  -
    >
      All of our submissions to WMT 2019 were ranked top in the human evaluation. Read our <a href="https://arxiv.org/abs/1907.06616">systems paper</a>, the <a href="https://ai.facebook.com/blog/facebook-leads-wmt-translation-competition/">blog post</a> and <a href="https://github.com/pytorch/fairseq/tree/master/examples/wmt19">download</a> the models.
---
<div class="page-header">
  <div class="row">
    <div class="col-sm-12">
      <h3>Michael Auli</h3>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-6">
      <address>
        Research Scientist Director<br/>
        <a href="http://research.facebook.com/ai">Facebook AI Research</a><br/>
        Menlo Park, CA<br/>
        <span class="glyphicon glyphicon-envelope"/> 1st.last@gmail.com<br/>
        <a href="https://scholar.google.com/citations?user=KMcwQtcAAAAJ&hl=en" style="text-decoration:none;"><img src="img/ico/gs.png" height="15" style="vertical-align:middle;" border="0">&nbsp; Google Scholar</a><br/>
        <a href="http://www.linkedin.com/in/michaelauli" style="text-decoration:none;"><img src="img/ico/linkedin.png" width="20" height="15" alt="LinkedIn" style="vertical-align:middle;" border="0">&nbsp;LinkedIn profile</a><br>
        <a href="http://www.twitter.com/michaelauli" style="text-decoration:none;"><img src="img/ico/twitter.jpeg" width="20" height="15" alt="Twitter" style="vertical-align:middle;" border="0">&nbsp;Twitter</a>
      </address>
    </div>
  </div>
</div>

<p>
  I am a Research Scientist Director at <a href="http://research.facebook.com/ai">Facebook AI Research</a> in Menlo Park where I work on speech processing and NLP which resulted in projects such as <a href="https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision/">wav2vec</a>, the <a href="https://github.com/pytorch/fairseq">fairseq toolkit</a>, the first modern <a href="https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation">convolutional seq2seq models</a> outperforming RNNs, as well as top ranked submissions at the WMT news translation task in <a href="https://arxiv.org/abs/1808.09381">2018</a> and <a href="https://ai.facebook.com/blog/facebook-leads-wmt-translation-competition">2019</a>. Before that I was at Microsoft Research, where I did early work on neural machine translation and neural dialogue models. I earned my Ph.D. at the University of Edinburgh where I was advised by Adam Lopez and Philipp Koehn.
</p>

<h4>News</h4>
<ul>
{% for item in page.news %}
  <li>{{ item }}</li>
{% endfor %}
</ul>
</br>

<h4>Selected Papers (See <a href="https://scholar.google.com/citations?user=KMcwQtcAAAAJ&hl=en">Google Scholar</a> for full list)</h4>
{% for post in site.papers %}
  {% if post.selected %}
    {% include paper.html paper=post %}
  {% endif %}
{% endfor %}

</br>
<h4>Press</h4>
{% for press in site.press %}
<div class="media">
  <div class="media-body">
    <a href="{{ press.url }}"><strong>{{ press.title }}</strong></a> {{ press.detail }}
  </div>
</div>
{% endfor %}

</br>
<h4>Talks</h4>
{% for talk in site.talks %}
<div class="media">
  <a class="pull-left thumbnail" {%if talk.url %} href="{{ talk.url }}" {% endif %}>
    <img class="media-object" src="img/talk/{{ talk.img }}" alt="">
  </a>
  <div class="media-body">
    <strong>{{ talk.title }}</strong><br/>
    {{ talk.detail }}
    {% if talk.video %}<br/>
      <a href="{{ talk.video }}"><span class="glyphicon glyphicon-film"></span></a> Video
    {% endif %}
  </div>
</div>
{% endfor %}
